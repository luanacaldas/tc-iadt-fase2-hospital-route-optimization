"""
Script principal para executar interface refatorada do chatbot.

Vers√£o 2.0 com:
- Layout otimizado (mapa em destaque)
- Chat funcional com Ollama
- Design profissional
- Funcionalidades completas
"""

import sys
from pathlib import Path
import webbrowser
import threading
import time

# Adicionar raiz do projeto ao PYTHONPATH
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

from hospital_routes.optimization.genetic_algorithm import GeneticAlgorithmOptimizer
from hospital_routes.visualization.map_generator import MapGenerator
from hospital_routes.visualization.chatbot_interface_v2 import ChatbotInterfaceV2
from hospital_routes.utils.accident_data import create_sample_accident_data
from hospital_routes.llm.ollama_helper import check_ollama_running, get_best_available_model
from seed_real_data import (
    generate_deliveries,
    generate_vehicles,
    get_optimization_config,
    get_depot_location,
)

try:
    from server_chatbot import set_optimization_context, run_server, FLASK_AVAILABLE
    SERVER_AVAILABLE = FLASK_AVAILABLE
except (ImportError, NameError):
    SERVER_AVAILABLE = False
    print("‚ö†Ô∏è Servidor backend n√£o dispon√≠vel. Interface funcionar√° em modo standalone.")


def main():
    """Fun√ß√£o principal."""
    print("=" * 70)
    print("ü§ñ Sistema de Chatbot - Interface Refatorada v2.0")
    print("=" * 70)
    print()
    
    # Verificar Ollama
    print("üîç Verificando Ollama...")
    if not check_ollama_running():
        print("‚ö†Ô∏è  Ollama n√£o est√° rodando.")
        print("   A interface funcionar√°, mas o chatbot pode n√£o responder corretamente.")
        print()
    else:
        model = get_best_available_model()
        if model:
            print(f"‚úÖ Ollama detectado! Modelo: {model}")
        else:
            print("‚ö†Ô∏è  Nenhum modelo Ollama dispon√≠vel.")
            print("   Execute: ollama pull llama3.2")
        print()
    
    # Carregar dados
    print("üì¶ Carregando dados...")
    deliveries = generate_deliveries()
    vehicles = generate_vehicles()
    config = get_optimization_config()
    depot = get_depot_location()
    print(f"‚úÖ {len(deliveries)} entregas, {len(vehicles)} ve√≠culos")
    print()
    
    # Otimizar
    print("‚öôÔ∏è  Otimizando rotas...")
    optimizer = GeneticAlgorithmOptimizer()
    result = optimizer.optimize(
        deliveries=deliveries,
        vehicles=vehicles,
        config=config,
        depot_location=depot,
    )
    print("‚úÖ Otimiza√ß√£o conclu√≠da!")
    print(f"   Dist√¢ncia total: {result.solution.total_distance:.2f} km")
    print(f"   Custo total: R$ {result.solution.total_cost:.2f}")
    print(f"   Ve√≠culos usados: {len(result.solution.routes)}")
    print()
    
    # Gerar mapa
    print("üó∫Ô∏è  Gerando mapa...")
    accident_provider = create_sample_accident_data()
    
    map_generator = MapGenerator()
    map_file = "route_map.html"
    map_generator.generate_map(
        optimization_result=result,
        deliveries=deliveries,
        depot_location=depot,
        output_path=map_file,
        title="Rotas Otimizadas - Sistema Hospitalar",
        accident_provider=accident_provider,
        show_accidents=True,
    )
    print(f"‚úÖ Mapa gerado: {map_file}")
    print()
    
    # Gerar interface refatorada
    print("üé® Gerando interface refatorada...")
    interface = ChatbotInterfaceV2(
        optimization_result=result,
        deliveries=deliveries,
        vehicles=vehicles,
        accident_provider=accident_provider,
    )
    
    interface_file = "chatbot_interface_v2.html"
    interface.generate_interface(
        output_path=interface_file,
        map_file=map_file,
        api_url="http://127.0.0.1:5000",
    )
    print(f"‚úÖ Interface gerada: {interface_file}")
    print()
    
    # Iniciar servidor backend (se dispon√≠vel)
    if SERVER_AVAILABLE:
        print("üöÄ Iniciando servidor backend...")
        set_optimization_context(result, deliveries, vehicles)
        
        # Iniciar servidor em thread separada
        server_thread = threading.Thread(
            target=run_server,
            args=('127.0.0.1', 5000, False),
            daemon=True,
        )
        server_thread.start()
        
        # Aguardar servidor iniciar
        time.sleep(2)
        print("‚úÖ Servidor backend rodando em http://127.0.0.1:5000")
        print()
    else:
        print("‚ö†Ô∏è  Modo standalone: O chatbot usa respostas simuladas.")
        print("   Para usar chatbot real, instale Flask: pip install flask flask-cors")
        print()
    
    # Abrir no navegador
    print("=" * 70)
    print("üåê Abrindo interface no navegador...")
    print("=" * 70)
    print()
    
    interface_path = Path(interface_file).absolute()
    webbrowser.open(f"file://{interface_path}")
    
    print("‚úÖ Interface aberta!")
    print()
    print("üí° Funcionalidades:")
    print("   - Mapa em destaque (70% da tela)")
    print("   - Chat funcional com Ollama")
    print("   - Estat√≠sticas compactas")
    print("   - Design profissional")
    print("   - Perguntas r√°pidas")
    print("   - Hist√≥rico de conversa")
    print()
    
    if SERVER_AVAILABLE:
        print("üì° Servidor backend rodando. Pressione Ctrl+C para parar.")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nüëã Encerrando servidor...")


if __name__ == '__main__':
    main()
